{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, Lambda, BatchNormalization, Dropout\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"Documents/datasetMRST/pres\"\n",
    "data=[]\n",
    "imagePaths = sorted(list(paths.list_images(dataset)))\n",
    "random.seed(42)\n",
    "\n",
    "random.shuffle(imagePaths)\n",
    "for imagePath in imagePaths:\n",
    "\n",
    "    image = cv2.imread(imagePath)\n",
    "\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "\n",
    "    image = rgb2gray(image)\n",
    "\n",
    "    data.append(image)\n",
    "    \n",
    "data_p = np.array(data, dtype=\"float\") / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f01c3ca2e80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_p[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_p[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to velocity datasetDocuments/datasetMRST/vel\n"
     ]
    }
   ],
   "source": [
    "dataset = input(\"datasetDocuments/datasetMRST/vel\")\n",
    "data=[]\n",
    "imagePaths = sorted(list(paths.list_images(dataset)))\n",
    "random.seed(42)\n",
    "\n",
    "random.shuffle(imagePaths)\n",
    "for imagePath in imagePaths:\n",
    "\n",
    "    image = cv2.imread(imagePath)\n",
    "\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "\n",
    "    image = rgb2gray(image)\n",
    "\n",
    "    data.append(image)\n",
    "    \n",
    "data_v = np.array(data, dtype=\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe184876130>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_v[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_v[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))\n",
    "x = Flatten()(input_img)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "encoded = Dense(2, activation='linear')(x)\n",
    "\n",
    "input_enc = Input(shape=(2,))\n",
    "d = Dense(64, activation='relu')(input_enc)\n",
    "d = Dense(28*28, activation='sigmoid')(d)\n",
    "decoded = Reshape((28, 28, 1))(d)\n",
    "\n",
    "encoder = keras.Model(input_img, encoded, name=\"encoder\")\n",
    "decoder = keras.Model(input_enc, decoded, name=\"decoder\")\n",
    "autoencoder = keras.Model(input_img, decoder(encoder(input_img)), name=\"autoencoder\")\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder (Functional)         (None, 2)                 108866    \n",
      "_________________________________________________________________\n",
      "decoder (Functional)         (None, 28, 28, 1)         51152     \n",
      "=================================================================\n",
      "Total params: 160,018\n",
      "Trainable params: 160,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0166\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0154\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0148\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0138\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0128\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0150\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0130\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0125\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0116\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0117\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0131\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0117\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0115\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0109\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0107\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0105\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0103\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0103\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0100\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0103\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0109\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0103\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0097\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0094\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0096\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0106\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0095\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0088\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0090\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0100\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0092\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0091\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0099\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0089\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0096\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0087\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0089\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0084\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0087\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0082\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0086\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0084\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0083\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0085\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0086\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0087\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0084\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0081\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0088\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0084\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0082\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0086\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0080\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0088\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 0.0086\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0082\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0085\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0079\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0083\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0082\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0080\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 0.0080\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe17818c160>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(data_p, data_v,\n",
    "                epochs=100,\n",
    "                batch_size=4,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = encoder.predict(data_p)\n",
    "a = plt.scatter(h[:, 0], h[:, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe17005d280>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = decoder.predict(np.expand_dims([0, -14], axis=0))\n",
    "plt.imshow(img.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 2\n",
    "batch_size = 2 # должно быть кратно \n",
    "\n",
    "def dropout_and_batch(x):\n",
    "  return Dropout(0.3)(BatchNormalization()(x))\n",
    "\n",
    "input_img = Input((28, 28, 1))\n",
    "x = Flatten()(input_img)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = dropout_and_batch(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = dropout_and_batch(x)\n",
    "\n",
    "z_mean = Dense(hidden_dim)(x)\n",
    "z_log_var = Dense(hidden_dim)(x) # подключаем два вектора - среднее и вариацию\n",
    "\n",
    "def noiser(args):\n",
    "  global z_mean, z_log_var\n",
    "  z_mean, z_log_var = args\n",
    "  N = K.random_normal(shape=(batch_size, hidden_dim), mean=0., stddev=1.0)\n",
    "  return K.exp(z_log_var / 2) * N + z_mean #формирование вектора скртыого состояни АШ\n",
    "\n",
    "h = Lambda(noiser, output_shape=(hidden_dim,))([z_mean, z_log_var]) #кастомный слой\n",
    "\n",
    "input_dec = Input(shape=(hidden_dim,))\n",
    "d = Dense(128, activation='relu')(input_dec)\n",
    "d = dropout_and_batch(d)\n",
    "d = Dense(256, activation='relu')(d)\n",
    "d = dropout_and_batch(d)\n",
    "d = Dense(28*28, activation='sigmoid')(d)\n",
    "decoded = Reshape((28, 28, 1))(d)\n",
    "\n",
    "encoder = keras.Model(input_img, h, name='encoder')\n",
    "decoder = keras.Model(input_dec, decoded, name='decoder')\n",
    "vae = keras.Model(input_img, decoder(encoder(input_img)), name=\"vae\")\n",
    "\n",
    "\n",
    "def vae_loss(x, y):\n",
    "  x = K.reshape(x, shape=(batch_size, 28*28))\n",
    "  y = K.reshape(y, shape=(batch_size, 28*28))\n",
    "  loss = K.sum(K.square(x-y), axis=-1)\n",
    "  kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1) # Дивергенция Кульбака-Лейблера-показывает расхождение нашей вероятности с нормальной\n",
    "  return loss + kl_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55/55 [==============================] - 1s 4ms/step - loss: 152.2169\n",
      "Epoch 2/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 128.0032\n",
      "Epoch 3/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 92.9287\n",
      "Epoch 4/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 50.6775\n",
      "Epoch 5/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 31.2797\n",
      "Epoch 6/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 24.4450\n",
      "Epoch 7/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 21.9758\n",
      "Epoch 8/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 20.4859\n",
      "Epoch 9/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 19.9070\n",
      "Epoch 10/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 18.3468\n",
      "Epoch 11/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 18.1841\n",
      "Epoch 12/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 18.9773\n",
      "Epoch 13/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 17.1010\n",
      "Epoch 14/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 17.0071\n",
      "Epoch 15/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 16.7718\n",
      "Epoch 16/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 18.9680\n",
      "Epoch 17/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 17.5884\n",
      "Epoch 18/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 17.2994\n",
      "Epoch 19/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 16.7484\n",
      "Epoch 20/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 17.7267\n",
      "Epoch 21/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 17.1431\n",
      "Epoch 22/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 16.7178\n",
      "Epoch 23/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.0111\n",
      "Epoch 24/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 16.3640\n",
      "Epoch 25/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 16.7508\n",
      "Epoch 26/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 16.3649\n",
      "Epoch 27/100\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 15.9424\n",
      "Epoch 28/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.8748\n",
      "Epoch 29/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.9104\n",
      "Epoch 30/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 16.0629\n",
      "Epoch 31/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 16.5364\n",
      "Epoch 32/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 16.1245\n",
      "Epoch 33/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 16.1072\n",
      "Epoch 34/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.4024\n",
      "Epoch 35/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.3326\n",
      "Epoch 36/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 16.6015\n",
      "Epoch 37/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 15.5713\n",
      "Epoch 38/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 14.5519\n",
      "Epoch 39/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.3188\n",
      "Epoch 40/100\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 16.5710\n",
      "Epoch 41/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 15.6625\n",
      "Epoch 42/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.6150\n",
      "Epoch 43/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.5484\n",
      "Epoch 44/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 14.1897\n",
      "Epoch 45/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.6143\n",
      "Epoch 46/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 14.8997\n",
      "Epoch 47/100\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 14.8578\n",
      "Epoch 48/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 13.9507\n",
      "Epoch 49/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 14.6324\n",
      "Epoch 50/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 14.7495\n",
      "Epoch 51/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.5047\n",
      "Epoch 52/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.6747\n",
      "Epoch 53/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.2425\n",
      "Epoch 54/100\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 14.3910\n",
      "Epoch 55/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.3189\n",
      "Epoch 56/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.0595\n",
      "Epoch 57/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 14.6017\n",
      "Epoch 58/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 15.8324\n",
      "Epoch 59/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.6148\n",
      "Epoch 60/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 15.7010\n",
      "Epoch 61/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.5074\n",
      "Epoch 62/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 15.2727\n",
      "Epoch 63/100\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 14.6708\n",
      "Epoch 64/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 14.1385\n",
      "Epoch 65/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 15.4196\n",
      "Epoch 66/100\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 15.3292\n",
      "Epoch 67/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.4007\n",
      "Epoch 68/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.5454\n",
      "Epoch 69/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.8113\n",
      "Epoch 70/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 14.0932\n",
      "Epoch 71/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 15.4848\n",
      "Epoch 72/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 15.4631\n",
      "Epoch 73/100\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 14.3082\n",
      "Epoch 74/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 14.8609\n",
      "Epoch 75/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 14.0664\n",
      "Epoch 76/100\n",
      "55/55 [==============================] - 0s 9ms/step - loss: 14.1272\n",
      "Epoch 77/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 14.0870\n",
      "Epoch 78/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.9279\n",
      "Epoch 79/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 15.3027\n",
      "Epoch 80/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 15.4118\n",
      "Epoch 81/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 14.8999\n",
      "Epoch 82/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 15.1386\n",
      "Epoch 83/100\n",
      "55/55 [==============================] - 1s 12ms/step - loss: 14.2944\n",
      "Epoch 84/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 14.6033\n",
      "Epoch 85/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 13.8228\n",
      "Epoch 86/100\n",
      "55/55 [==============================] - 0s 9ms/step - loss: 14.6705\n",
      "Epoch 87/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 13.5569\n",
      "Epoch 88/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 15.1026\n",
      "Epoch 89/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 14.5634\n",
      "Epoch 90/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 13.5157\n",
      "Epoch 91/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 14.4003\n",
      "Epoch 92/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 14.4004\n",
      "Epoch 93/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 14.5741\n",
      "Epoch 94/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 14.2975\n",
      "Epoch 95/100\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 15.2467\n",
      "Epoch 96/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 14.9838\n",
      "Epoch 97/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 14.3480\n",
      "Epoch 98/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 15.6233\n",
      "Epoch 99/100\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 13.8789\n",
      "Epoch 100/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 14.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe160c03be0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "\n",
    "vae.fit(data_p, data_v, epochs=100, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe16014e460>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "h = encoder.predict(data_p, batch_size=batch_size)\n",
    "plt.scatter(h[:, 0], h[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe15ae5b4f0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = decoder.predict(np.expand_dims([0, 0], axis=0))\n",
    "plt.imshow(img.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 28, 28, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 14, 14, 32)   896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 7, 7, 64)     18496       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           50192       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sampling (Sampling)             (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 69,652\n",
      "Trainable params: 69,652\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 3))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         289       \n",
      "=================================================================\n",
      "Total params: 65,089\n",
      "Trainable params: 65,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-16-373258cf77cd>:22 train_step\n        z_mean, z_log_var, z = self.encoder(data)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:204 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer encoder expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(2, 28, 28, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(2, 28, 28, 3) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5da685d3356f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_v\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-16-373258cf77cd>:22 train_step\n        z_mean, z_log_var, z = self.encoder(data)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:204 assert_input_compatibility\n        raise ValueError('Layer ' + layer_name + ' expects ' +\n\n    ValueError: Layer encoder expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(2, 28, 28, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(2, 28, 28, 3) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(data_p, data_v , epochs=3, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_p = np.reshape(data_p, (len(data_p), 64, 64, 3))\n",
    "data_v  = np.reshape(data_v,  (len(data_v),  64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged, input_shape = [4096], output_shape = [64, 64, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a845bbe954d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout_and_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'encoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    952\u001b[0m                                                 input_list)\n\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1088\u001b[0m           layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1091\u001b[0m             inputs, input_masks, args, kwargs)\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    555\u001b[0m       \u001b[0;31m# Set the static shape for the result since it might lost during array_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m       \u001b[0;31m# reshape, eg, some `None` dim in the result could be inferred.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m       \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m       output_shape += self._fix_unknown_dimension(input_shape[1:],\n\u001b[0m\u001b[1;32m    548\u001b[0m                                                   self.target_shape)\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36m_fix_unknown_dimension\u001b[0;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[1;32m    534\u001b[0m       \u001b[0moutput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mknown\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged, input_shape = [4096], output_shape = [64, 64, 3]"
     ]
    }
   ],
   "source": [
    "hidden_dim = 2\n",
    "batch_size = 2 # должно быть кратно 110\n",
    "\n",
    "def dropout_and_batch(x):\n",
    "    return Dropout(0.3)(BatchNormalization()(x))\n",
    "\n",
    "\n",
    "input_img = Input((28, 28, 3))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "\n",
    "z_mean = Dense(hidden_dim)(x)\n",
    "z_log_var = Dense(hidden_dim)(x)\n",
    "\n",
    "def noiser(args):\n",
    "    global z_mean, z_log_var\n",
    "    z_mean, z_log_var = args\n",
    "    N = K.random_normal(shape=(batch_size, hidden_dim), mean=0., stddev=1.0)\n",
    "    return K.exp(z_log_var / 2) * N + z_mean\n",
    "\n",
    "h = Lambda(noiser, output_shape=(hidden_dim,))([z_mean, z_log_var])\n",
    "\n",
    "input_dec = Input(shape=(hidden_dim,))\n",
    "d = Dense(128, activation='relu')(input_dec)\n",
    "d = dropout_and_batch(d)\n",
    "d = Dense(256, activation='relu')(d)\n",
    "d = dropout_and_batch(d)\n",
    "d = Dense(64*64, activation='sigmoid')(d)\n",
    "decoded = Reshape((64, 64, 3))(d)\n",
    "\n",
    "encoder = keras.Model(input_img, h, name='encoder')\n",
    "decoder = keras.Model(input_dec, decoded, name='decoder')\n",
    "vae = keras.Model(input_img, decoder(encoder(input_img)), name=\"vae\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vae_loss(x, y):\n",
    "    x = K.reshape(x, shape=(batch_size, 28*28))\n",
    "    y = K.reshape(y, shape=(batch_size, 28*28))\n",
    "    loss = K.sum(K.square(x-y), axis=-1)\n",
    "    kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return loss + kl_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "\n",
    "vae.fit(data_p, data_v epochs=5, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = encoder.predict(x_test[:6000], batch_size=batch_size)\n",
    "plt.scatter(h[:, 0], h[:, 1])\n",
    "\n",
    "\n",
    "n = 5\n",
    "total = 2*n+1\n",
    "\n",
    "plt.figure(figsize=(total, total))\n",
    "\n",
    "num = 1\n",
    "for i in range(-n, n+1):\n",
    "    for j in range(-n, n+1):\n",
    "        ax = plt.subplot(total, total, num)\n",
    "        num += 1\n",
    "        img = decoder.predict(np.expand_dims([3*i/n, 3*j/n], axis=0))\n",
    "        plt.imshow(img.squeeze(), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           [(None, 28, 28, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 14, 14, 32)   896         input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 7, 7, 64)     18496       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 3136)         0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 16)           50192       flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            34          dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            34          dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sampling_2 (Sampling)           (None, 2)            0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 69,652\n",
      "Trainable params: 69,652\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 3))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DT (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DT (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DT (None, 28, 28, 3)         99        \n",
      "=================================================================\n",
      "Total params: 64,899\n",
      "Trainable params: 64,899\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(3, 1, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-61-373258cf77cd>:22 train_step\n        z_mean, z_log_var, z = self.encoder(data)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer encoder: expected shape=(None, 28, 28, 3), found shape=(2, 64, 64, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-5cc877c3735e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    <ipython-input-61-373258cf77cd>:22 train_step\n        z_mean, z_log_var, z = self.encoder(data)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/hwu/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer encoder: expected shape=(None, 28, 28, 3), found shape=(2, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(data_p, epochs=5, batch_size=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
